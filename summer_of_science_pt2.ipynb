{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation of Solar Corona Images from Solar Dynamic Observatory <br>\n",
    "Francesco Carella and George Miloshevich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "colab = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intro**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's import some useful libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Plot the data <br>\n",
    "### Full Disk Images <br>\n",
    "In this section we plot the original data of the Sun in different wavelenghts from the Solar Dynamic Observatory. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Wavelenghts <br>\n",
    "In this section we plot the original data of the Sun in different wavelenghts from the Solar Dynamic Observatory. Here there is an example on how to plot the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the colormap\n",
    "cm_193 = pickle.load(open('./SoS-ML4-Sun/aia193_colormap.pkl', 'rb'))\n",
    "\n",
    "#Load the data (Here you have 193 A channel from SDO)\n",
    "sdo_193 = np.load('./SoS-ML4-Sun/data/2012_05_07T12_00_07_84_193.npy')\n",
    "\n",
    "#Plot the image\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.log10(sdo_193), cmap=cm_193)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "#Here we have used np.log10 to enhance the contrast of the image. Try to remove it and see the difference. Try also to use a different function to\n",
    "#enhance the contrast of the image, such as np.sqrt, np.log, np.log2, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot all the different wavelenghts. What are the differences? Can you see different structures? If so, why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continue yourself ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the HMI Magnetogram. Which are the differences with the previous wavelenghts? What is enlightened the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = 'gray'\n",
    "\n",
    "#continue yourself ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed Images <br>\n",
    "Here we plot the tranformed images. What are the differences with respect to the original ones? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = np.load('./SoS-ML4-Sun/data/2012_05_07T12_00_07_84.npy')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(np.log10(transformed_data[3]), cmap=cm_193)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformed Images: Plot different wavelenghts <br>\n",
    "As you have done before, plot all the different wavelenghts and magnetogram. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Preparation (Pre-Processing) <br>\n",
    "### Scaling\n",
    "Machine Learning tools are sensitive to the scale of the input features. You may end up having some features that are predominant just because, for example, are orders of magnitude bigger than others. Scaling of a dataset is a common requirement for many machine learning estimators. By scaling one mean that all the data are somehow normalized such that there is no predominant feature. The easiest thing to do, for example, can be just dividing all your values by the maximum value that you have in your image.<br>\n",
    "Here, we will use a Standard Scaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler\n",
    "The `StandardScaler` is a feature scaling technique provided by the `sklearn.preprocessing` module in Python. It standardizes features by removing the mean and scaling to unit variance. This process results in a distribution with a mean of 0 and a standard deviation of 1 for each feature, which is a common requirement for many machine learning algorithms.\n",
    "\n",
    "Mathematically, it transforms the data using the formula:\n",
    "\n",
    "$ z = \\frac{x - \\mu}{\\sigma} $\n",
    "\n",
    "where:\n",
    "- $ x $ is the original feature value,\n",
    "- $ \\mu $ is the mean of the feature,\n",
    "- $ \\sigma $ is the standard deviation of the feature.\n",
    "\n",
    "### When to Use Standard Scaler\n",
    "\n",
    "- When you have features with different units or scales.\n",
    "- When your machine learning algorithm assumes normally distributed data.\n",
    "- To improve the performance and training stability of many algorithms, including linear regression, logistic regression, and neural networks.\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Sample data\n",
    "data = [[-1, 2], [-0.5, 6], [0, 10], [1, 18]]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's scale the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data has to be flattened before giving it to the model (K-Means) and before scaling. Here's how to do it\n",
    "flat94 = transformed_data[0].flatten()\n",
    "flat171 = transformed_data[1].flatten()\n",
    "flat193 = transformed_data[2].flatten()\n",
    "flat211 = transformed_data[3].flatten()\n",
    "flat304 = transformed_data[4].flatten()\n",
    "flathmi = transformed_data[5].flatten()\n",
    "\n",
    "data = np.stack((flat94, flat171, flat193, flat211, flat304, flathmi), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Segmentation with K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Select the number of clusters\n",
    "nc = 3\n",
    "\n",
    "#Run K-Means\n",
    "km = KMeans(n_clusters=nc, random_state=42).fit(data).predict(data)\n",
    "labels = km.labels_ #these are the labels of the clusters\n",
    "\n",
    "#Plot the clustered image\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(labels.reshape(sdo_193.shape), cmap='tab20')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try yourself with several different number of clusters. What is the best one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Have fun with the Sun!\n",
    "   _____  \n",
    "  /     \\ \n",
    " | x   x |\n",
    " |   ^   |\n",
    " | \\___/ |\n",
    "  \\_____/\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conflux",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
